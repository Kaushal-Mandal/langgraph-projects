{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ce405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, List, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "from dotenv import load_dotenv\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "tavily_search = TavilySearchResults(max_results=2)\n",
    "python_repl_tool = PythonREPLTool()\n",
    "\n",
    "python_repl_tool.invoke('x=5; print(x)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervisor(BaseModel):\n",
    "    next:Literal['enhancer', 'researcher','coder'] = Field(\n",
    "        description=\"Determines which specialist to activate next in the workflow sequence:\"\n",
    "        \"'enhancer' when user input requires clarification, expansion, or refinement,\"\n",
    "        \"'researcher' when additional facts, context, or data collection is necessary,\"\n",
    "        \"'coder' when implementation, computation, or technical problem-solving is required.\"\n",
    "    )\n",
    "    reason:str = Field(\n",
    "        description=\"Detailed justification for the routing decision, explaining the rationale behind selecting the \" \\\n",
    "        \"particular specialist and how this advances the task toward completion.\"\n",
    "    )\n",
    "\n",
    "def supervisor_node(state:MessagesState) -> Command[Literal['enhancer', 'researcher','coder']]:\n",
    "    system_prompt = ('''\n",
    "                     You are a workflow supervisor managing a team of three specialized agents: Prompt Enhancer, Researcher, and Coder.\n",
    "                     Your role is to orchestrate the workflow by selecting the most appropriate next agent based on the current state\n",
    "                     and needs of the task. Provide a clear, concise rationale for each decision to ensure transparency in your\n",
    "                     decision-making process.\n",
    "                     **Team Members**:\n",
    "                     1. **Prompt Enhancer**: Always consider this agent first. They clarify ambiguous requests, improve poorly \n",
    "                     defined queries, and ensure the task is well-structured before deeper processing begins.\n",
    "                     2. **Researcher**: Specializes in information gathering, fact-finding, and collecting relevant data needed \n",
    "                     to address the user's request.\n",
    "                     3. **Coder**: Focuses on technical implementation, calculations, data analysis, algorithm development, and \n",
    "                     coding solutions.\n",
    "\n",
    "                     **Your Responsibilities**:\n",
    "                     1. Analyze each user request and agent response for completeness, accuracy, and relevance.\n",
    "                     2. Route the task to the most appropriate agent at each decision point.\n",
    "                     3. Maintain workflow momentum by avoiding redundant agent assignments.\n",
    "                     4. Continue the process until the user's request is fully and satisfactorily resolved.\n",
    "\n",
    "                     Your objective is to create an efficient workflow that leverages each agent's strengths while minimizing \n",
    "                     unnecessary steps, ultimately delivering complete and accurate solutions to user request.\n",
    "    ''')\n",
    "\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "    ] + state['messages']\n",
    "    response = llm.with_structured_output(Supervisor).invoke(messages)\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    print(f'--Workflow Transition : Supervisor -> {goto.upper()} --')\n",
    "\n",
    "    return Command(\n",
    "        update= {\n",
    "            'messages': [\n",
    "                HumanMessage(content=reason, name='supervisor')\n",
    "            ]\n",
    "        },\n",
    "        goto=goto,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhancer_node(state:MessagesState) -> Command[Literal['supervisor']]:\n",
    "    \"\"\"\n",
    "        Enhancer agent node that improves and clarifies user queries.\n",
    "        Takes the original user input and transforms it into a more precise, actionale request passing it to the supervisor.\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "        \"You are a Query Refinement Specialist with expertise in transforming vague requests into precise instructions. \"\n",
    "        \"Your responsibilities include: \\n\"\n",
    "        \"1. Analyzing the original query to identify key intent and requirements\\n\"\n",
    "        \"2. Resolving any ambiguities without requesting additional user input\\n\"\n",
    "        \"3. Expanding underdeveloped aspects of the query with reasonable assumptions\\n\"\n",
    "        \"4. Restructuring the query for clarity and actionability\\n\"\n",
    "        \"5. Ensuring all technical terminology is properly defined in context \\n\"\n",
    "        \"Important: Never ask questions back to the user. Instead, make informed assumptions and create the most comprehensive \"\n",
    "        \"version of their request possible.\"\n",
    "    )\n",
    "    messages = [\n",
    "        {'role':'system','content':system_prompt},\n",
    "    ] + state['messages']\n",
    "\n",
    "    enhanced_query = llm.invoke(messages)\n",
    "    print(f'----- Workflow Transition :  Prompt Enhancer -> Supervisor -----')\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            'messages':[HumanMessage(content=enhanced_query.content,\n",
    "                                     name='enhancer')]\n",
    "        },\n",
    "        goto='supervisor',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae64ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state:MessagesState) -> Command[Literal['validator']]:\n",
    "    \"\"\"\n",
    "        Research agent node that gathers information using Tavily search. Takes the current task state, performs relevant \n",
    "        research, and returns findings for validation.\n",
    "    \"\"\"\n",
    "    research_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[tavily_search],\n",
    "        state_modifier = \"you are and Information Specialist with expertise in comprehensive research. Your responsibilities includes:\\n\"\n",
    "            \"1. Identifying key information needs based on the query context\\n\"\n",
    "            \"2. Gathering relevant, accurate, and up-to-date information from reliable sources\\n\"\n",
    "            \"3. Organizing findings in a structured, easily digestible format\\n\"\n",
    "            \"4. Citing sources when possible to establish credibility\\n\"\n",
    "            \"5. Focusing exclusively on information gathering - avoid analysis or implementation\\n\"\n",
    "            \"provide thorough, factual responses without speculation where information is unavailable.\"\n",
    "    )\n",
    "    result = research_agent.invoke(state)\n",
    "    print(f' ---- Workflow Transition :  Researcher -> Validator ----')\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            'messages': [\n",
    "                HumanMessage(\n",
    "                    content=result['messages'][-1].content,\n",
    "                    name='researcher'\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto='validator',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0baf7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_node(state:MessagesState) -> Command[Literal['validator']]:\n",
    "    code_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[python_repl_tool],\n",
    "        state_modifier=(\n",
    "            'You are a coder and analyst. Focus on mathematical calculations, analyzing, solving math questions,' \\\n",
    "            'and executing code. Handle technical problem-solving and data tasks.'\n",
    "        )\n",
    "    )\n",
    "    result = code_agent.invoke(state)\n",
    "    print(f'----Workflow Transition: Coder -> Validator ----')\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            'messages': [HumanMessage(\n",
    "                content=result['messages'][-1].content, name='coder'\n",
    "            )]\n",
    "        },\n",
    "        goto='validator',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790634e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#System prompt providing clear instructions to the validator agent\n",
    "\n",
    "system_prompt = '''\n",
    "    Your task is to ensure reasonable quality.\n",
    "    Specifically, you must:\n",
    "    - Review the user's question (the first message in the workflow).\n",
    "    - Review the answer (the last message in the workflow).\n",
    "    - If the answer addresses the core intent of the question, even if not perfectly, signal to end the workflow with 'FINISH'.\n",
    "    - Only route back to the supervisor if the answer is completely off-topic, harmful, or fundamentally misunderstands the question.\n",
    "\n",
    "    - Accept answers that are 'good enough' rather than perfect\n",
    "    - Prioritize workflow completion over perfect responses\n",
    "    - Give benefit of doubt to borderline answers\n",
    "\n",
    "    Routing Guidelines:\n",
    "    1. 'supervisor' Agent: ONLY for responses that are completely incorrect or off-topic.\n",
    "    2. Respond with 'FINISH' in all other cases to end the workflow.\n",
    "'''\n",
    "\n",
    "class Validator(BaseModel):\n",
    "    next: Literal['supervisor', 'FINISH'] = Field(\n",
    "        description=\"Specifies the next worker in the pipeline: 'supervisor' to continue or 'FINISH' to terminate.\"\n",
    "    )\n",
    "    reason: str=Field(\n",
    "        description='The reason for the decision.'\n",
    "    )\n",
    "\n",
    "def validator_node(state:MessagesState) -> Command[Literal['supervisor', '__end__']]:\n",
    "    user_question = state['messages'][0].content\n",
    "    agent_answer = state['message'][-1].content\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            'role':'system','content':system_prompt\n",
    "        },\n",
    "        {\n",
    "            'role':'user','content':user_question\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant','content':agent_answer\n",
    "        },\n",
    "    ]\n",
    "    response = llm.with_structured_output(Validator).invoke(messages)\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    if goto == 'FINISH' or goto == END:\n",
    "        goto = END\n",
    "        print('--- Transitioning to END ---')\n",
    "    else:\n",
    "        print(f'--- Workflow Transition : Validator -> Supervisor ---')\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            'messages': [\n",
    "                HumanMessage(content=reason, name = 'validator')\n",
    "            ]\n",
    "        },\n",
    "        goto=goto,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0365ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node('supervisor', supervisor_node)\n",
    "graph.add_node('enhancer', enhancer_node)\n",
    "graph.add_node('researcher', research_node)\n",
    "graph.add_node('coder', code_node)\n",
    "graph.add_node('validator', validator_node)\n",
    "\n",
    "graph.add_edge(START, 'supervisor')\n",
    "app = graph.compile()\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1795099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    'messages': [\n",
    "        ('user', 'Give me 12th prime numbers'),\n",
    "    ]\n",
    "}\n",
    "\n",
    "for step in app.stream(inputs):\n",
    "    for key, value in step.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(value, indent=2, width=57, depth=None)\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
